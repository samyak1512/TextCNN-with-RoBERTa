{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/samyak15jain/textcnn-with-roberta?scriptVersionId=135130743\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"690d4f1f-a77a-4e84-b22c-9cf5a99a574a","_cell_guid":"0ea8d69a-e5e1-4c1d-99ac-1a58f90ecb58","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-28T10:36:19.063745Z","iopub.execute_input":"2023-06-28T10:36:19.064033Z","iopub.status.idle":"2023-06-28T10:36:19.08768Z","shell.execute_reply.started":"2023-06-28T10:36:19.064007Z","shell.execute_reply":"2023-06-28T10:36:19.08664Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/glovetwitter27b100dtxt/glove.twitter.27B.100d.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\n\n# Download all NLTK resources\nnltk.download('all')","metadata":{"_uuid":"66fa5f0d-745f-4ceb-abeb-4033326658df","_cell_guid":"7396ea7f-ae94-4093-a730-cc33d687df5d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-28T10:36:19.089633Z","iopub.execute_input":"2023-06-28T10:36:19.08999Z","iopub.status.idle":"2023-06-28T10:36:39.645086Z","shell.execute_reply.started":"2023-06-28T10:36:19.089937Z","shell.execute_reply":"2023-06-28T10:36:39.644146Z"},"scrolled":true,"_kg_hide-output":true,"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading collection 'all'\n[nltk_data]    | \n[nltk_data]    | Downloading package abc to /usr/share/nltk_data...\n[nltk_data]    |   Package abc is already up-to-date!\n[nltk_data]    | Downloading package alpino to /usr/share/nltk_data...\n[nltk_data]    |   Package alpino is already up-to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping\n[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n[nltk_data]    | Downloading package basque_grammars to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package basque_grammars is already up-to-date!\n[nltk_data]    | Downloading package bcp47 to /usr/share/nltk_data...\n[nltk_data]    | Downloading package biocreative_ppi to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n[nltk_data]    | Downloading package bllip_wsj_no_aux to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n[nltk_data]    | Downloading package book_grammars to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package book_grammars is already up-to-date!\n[nltk_data]    | Downloading package brown to /usr/share/nltk_data...\n[nltk_data]    |   Package brown is already up-to-date!\n[nltk_data]    | Downloading package brown_tei to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package brown_tei is already up-to-date!\n[nltk_data]    | Downloading package cess_cat to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package cess_cat is already up-to-date!\n[nltk_data]    | Downloading package cess_esp to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package cess_esp is already up-to-date!\n[nltk_data]    | Downloading package chat80 to /usr/share/nltk_data...\n[nltk_data]    |   Package chat80 is already up-to-date!\n[nltk_data]    | Downloading package city_database to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package city_database is already up-to-date!\n[nltk_data]    | Downloading package cmudict to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package cmudict is already up-to-date!\n[nltk_data]    | Downloading package comparative_sentences to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n[nltk_data]    | Downloading package comtrans to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package comtrans is already up-to-date!\n[nltk_data]    | Downloading package conll2000 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package conll2000 is already up-to-date!\n[nltk_data]    | Downloading package conll2002 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package conll2002 is already up-to-date!\n[nltk_data]    | Downloading package conll2007 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package conll2007 is already up-to-date!\n[nltk_data]    | Downloading package crubadan to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package crubadan is already up-to-date!\n[nltk_data]    | Downloading package dependency_treebank to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package dependency_treebank is already up-to-date!\n[nltk_data]    | Downloading package dolch to /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/dolch.zip.\n[nltk_data]    | Downloading package europarl_raw to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package europarl_raw is already up-to-date!\n[nltk_data]    | Downloading package extended_omw to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package floresta to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package floresta is already up-to-date!\n[nltk_data]    | Downloading package framenet_v15 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n[nltk_data]    | Downloading package framenet_v17 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n[nltk_data]    | Downloading package gazetteers to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package gazetteers is already up-to-date!\n[nltk_data]    | Downloading package genesis to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package genesis is already up-to-date!\n[nltk_data]    | Downloading package gutenberg to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package gutenberg is already up-to-date!\n[nltk_data]    | Downloading package ieer to /usr/share/nltk_data...\n[nltk_data]    |   Package ieer is already up-to-date!\n[nltk_data]    | Downloading package inaugural to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package inaugural is already up-to-date!\n[nltk_data]    | Downloading package indian to /usr/share/nltk_data...\n[nltk_data]    |   Package indian is already up-to-date!\n[nltk_data]    | Downloading package jeita to /usr/share/nltk_data...\n[nltk_data]    |   Package jeita is already up-to-date!\n[nltk_data]    | Downloading package kimmo to /usr/share/nltk_data...\n[nltk_data]    |   Package kimmo is already up-to-date!\n[nltk_data]    | Downloading package knbc to /usr/share/nltk_data...\n[nltk_data]    |   Package knbc is already up-to-date!\n[nltk_data]    | Downloading package large_grammars to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package large_grammars is already up-to-date!\n[nltk_data]    | Downloading package lin_thesaurus to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n[nltk_data]    | Downloading package mac_morpho to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package mac_morpho is already up-to-date!\n[nltk_data]    | Downloading package machado to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package machado is already up-to-date!\n[nltk_data]    | Downloading package masc_tagged to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package masc_tagged is already up-to-date!\n[nltk_data]    | Downloading package maxent_ne_chunker to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | Downloading package moses_sample to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package moses_sample is already up-to-date!\n[nltk_data]    | Downloading package movie_reviews to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package movie_reviews is already up-to-date!\n[nltk_data]    | Downloading package mte_teip5 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package mte_teip5 is already up-to-date!\n[nltk_data]    | Downloading package mwa_ppdb to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n[nltk_data]    | Downloading package names to /usr/share/nltk_data...\n[nltk_data]    |   Package names is already up-to-date!\n[nltk_data]    | Downloading package nombank.1.0 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package nonbreaking_prefixes to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n[nltk_data]    | Downloading package nps_chat to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package nps_chat is already up-to-date!\n[nltk_data]    | Downloading package omw to /usr/share/nltk_data...\n[nltk_data]    |   Package omw is already up-to-date!\n[nltk_data]    | Downloading package omw-1.4 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package opinion_lexicon to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n[nltk_data]    | Downloading package panlex_swadesh to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package paradigms to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package paradigms is already up-to-date!\n[nltk_data]    | Downloading package pe08 to /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/pe08.zip.\n[nltk_data]    | Downloading package perluniprops to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping misc/perluniprops.zip.\n[nltk_data]    | Downloading package pil to /usr/share/nltk_data...\n[nltk_data]    |   Package pil is already up-to-date!\n[nltk_data]    | Downloading package pl196x to /usr/share/nltk_data...\n[nltk_data]    |   Package pl196x is already up-to-date!\n[nltk_data]    | Downloading package porter_test to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package porter_test is already up-to-date!\n[nltk_data]    | Downloading package ppattach to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package ppattach is already up-to-date!\n[nltk_data]    | Downloading package problem_reports to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package problem_reports is already up-to-date!\n[nltk_data]    | Downloading package product_reviews_1 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n[nltk_data]    | Downloading package product_reviews_2 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n[nltk_data]    | Downloading package propbank to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package propbank is already up-to-date!\n[nltk_data]    | Downloading package pros_cons to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package pros_cons is already up-to-date!\n[nltk_data]    | Downloading package ptb to /usr/share/nltk_data...\n[nltk_data]    |   Package ptb is already up-to-date!\n[nltk_data]    | Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]    |   Package punkt is already up-to-date!\n[nltk_data]    | Downloading package qc to /usr/share/nltk_data...\n[nltk_data]    |   Package qc is already up-to-date!\n[nltk_data]    | Downloading package reuters to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package reuters is already up-to-date!\n[nltk_data]    | Downloading package rslp to /usr/share/nltk_data...\n[nltk_data]    |   Package rslp is already up-to-date!\n[nltk_data]    | Downloading package rte to /usr/share/nltk_data...\n[nltk_data]    |   Package rte is already up-to-date!\n[nltk_data]    | Downloading package sample_grammars to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package sample_grammars is already up-to-date!\n[nltk_data]    | Downloading package semcor to /usr/share/nltk_data...\n[nltk_data]    |   Package semcor is already up-to-date!\n[nltk_data]    | Downloading package senseval to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package senseval is already up-to-date!\n[nltk_data]    | Downloading package sentence_polarity to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package sentence_polarity is already up-to-date!\n[nltk_data]    | Downloading package sentiwordnet to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package sentiwordnet is already up-to-date!\n[nltk_data]    | Downloading package shakespeare to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package shakespeare is already up-to-date!\n[nltk_data]    | Downloading package sinica_treebank to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package sinica_treebank is already up-to-date!\n[nltk_data]    | Downloading package smultron to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package smultron is already up-to-date!\n[nltk_data]    | Downloading package snowball_data to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package snowball_data is already up-to-date!\n[nltk_data]    | Downloading package spanish_grammars to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package spanish_grammars is already up-to-date!\n[nltk_data]    | Downloading package state_union to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package state_union is already up-to-date!\n[nltk_data]    | Downloading package stopwords to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package stopwords is already up-to-date!\n[nltk_data]    | Downloading package subjectivity to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package subjectivity is already up-to-date!\n[nltk_data]    | Downloading package swadesh to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package swadesh is already up-to-date!\n[nltk_data]    | Downloading package switchboard to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package switchboard is already up-to-date!\n[nltk_data]    | Downloading package tagsets to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package tagsets is already up-to-date!\n[nltk_data]    | Downloading package timit to /usr/share/nltk_data...\n[nltk_data]    |   Package timit is already up-to-date!\n[nltk_data]    | Downloading package toolbox to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package toolbox is already up-to-date!\n[nltk_data]    | Downloading package treebank to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package treebank is already up-to-date!\n[nltk_data]    | Downloading package twitter_samples to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package twitter_samples is already up-to-date!\n[nltk_data]    | Downloading package udhr to /usr/share/nltk_data...\n[nltk_data]    |   Package udhr is already up-to-date!\n[nltk_data]    | Downloading package udhr2 to /usr/share/nltk_data...\n[nltk_data]    |   Package udhr2 is already up-to-date!\n[nltk_data]    | Downloading package unicode_samples to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package unicode_samples is already up-to-date!\n[nltk_data]    | Downloading package universal_tagset to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package universal_tagset is already up-to-date!\n[nltk_data]    | Downloading package universal_treebanks_v20 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n[nltk_data]    |       date!\n[nltk_data]    | Downloading package vader_lexicon to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package vader_lexicon is already up-to-date!\n[nltk_data]    | Downloading package verbnet to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package verbnet is already up-to-date!\n[nltk_data]    | Downloading package verbnet3 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n[nltk_data]    | Downloading package webtext to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package webtext is already up-to-date!\n[nltk_data]    | Downloading package wmt15_eval to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n[nltk_data]    | Downloading package word2vec_sample to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package word2vec_sample is already up-to-date!\n[nltk_data]    | Downloading package wordnet to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package wordnet is already up-to-date!\n[nltk_data]    | Downloading package wordnet2021 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package wordnet2022 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n[nltk_data]    | Downloading package wordnet31 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package wordnet_ic to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package wordnet_ic is already up-to-date!\n[nltk_data]    | Downloading package words to /usr/share/nltk_data...\n[nltk_data]    |   Package words is already up-to-date!\n[nltk_data]    | Downloading package ycoe to /usr/share/nltk_data...\n[nltk_data]    |   Package ycoe is already up-to-date!\n[nltk_data]    | \n[nltk_data]  Done downloading collection all\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"! unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"_uuid":"385a4b41-3914-4fe3-ab53-76ca0d8046e9","_cell_guid":"357b5167-88aa-4b54-9b96-0ae14cb12d0c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-28T10:36:39.646641Z","iopub.execute_input":"2023-06-28T10:36:39.647336Z","iopub.status.idle":"2023-06-28T10:36:41.046876Z","shell.execute_reply.started":"2023-06-28T10:36:39.647302Z","shell.execute_reply":"2023-06-28T10:36:41.04578Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Archive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"}]},{"cell_type":"code","source":"# from torchtext import vocab\n# vec = vocab.Vectors('glove.6B.100d.txt', '../input/glove6b100dtxt/')","metadata":{"_uuid":"54485369-b57e-49ef-b880-03cce87b6f2c","_cell_guid":"1de0728a-d80f-41d9-9695-0074e11bdd5f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-28T10:36:41.049831Z","iopub.execute_input":"2023-06-28T10:36:41.050314Z","iopub.status.idle":"2023-06-28T10:36:41.05481Z","shell.execute_reply.started":"2023-06-28T10:36:41.050273Z","shell.execute_reply":"2023-06-28T10:36:41.053922Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import wandb\n\nwandb.init(project='MYM TWEETS ANALYSIS')","metadata":{"_uuid":"980eaa9c-adde-480d-afca-8d2a48c3c767","_cell_guid":"db6fb848-5b54-4dd2-82a8-f5dd97286407","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-28T10:36:41.057973Z","iopub.execute_input":"2023-06-28T10:36:41.060311Z","iopub.status.idle":"2023-06-28T10:37:34.457817Z","shell.execute_reply.started":"2023-06-28T10:36:41.060199Z","shell.execute_reply":"2023-06-28T10:37:34.456959Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230628_103703-919gmktv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samyak152002/MYM%20TWEETS%20ANALYSIS/runs/919gmktv' target=\"_blank\">usual-resonance-3</a></strong> to <a href='https://wandb.ai/samyak152002/MYM%20TWEETS%20ANALYSIS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samyak152002/MYM%20TWEETS%20ANALYSIS' target=\"_blank\">https://wandb.ai/samyak152002/MYM%20TWEETS%20ANALYSIS</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samyak152002/MYM%20TWEETS%20ANALYSIS/runs/919gmktv' target=\"_blank\">https://wandb.ai/samyak152002/MYM%20TWEETS%20ANALYSIS/runs/919gmktv</a>"},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/samyak152002/MYM%20TWEETS%20ANALYSIS/runs/919gmktv?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x793c20872fe0>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\nimport random\nimport nltk\nimport torchtext.vocab\nfrom nltk.corpus import wordnet\nfrom torchtext.vocab import GloVe","metadata":{"_uuid":"0d1d4c9d-31ca-48c1-a067-0daf53a4ca79","_cell_guid":"36fa75df-4338-4219-a792-e0c696782f28","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-28T10:39:15.836736Z","iopub.execute_input":"2023-06-28T10:39:15.837122Z","iopub.status.idle":"2023-06-28T10:39:16.461752Z","shell.execute_reply.started":"2023-06-28T10:39:15.837092Z","shell.execute_reply":"2023-06-28T10:39:16.460428Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport urllib.request\n\n# Define the sample input text\nsample_text = \"I dilike abortions\"\n\n# Preprocess text (username and link placeholders)\ndef preprocess(text):\n    new_text = []\n    for t in text.split(\" \"):\n        t = '@user' if t.startswith('@') and len(t) > 1 else t\n        t = 'http' if t.startswith('http') else t\n        new_text.append(t)\n    return \" \".join(new_text)\n\n# Preprocess the sample input text\npreprocessed_text = preprocess(sample_text)\n\n# Load the tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-stance-abortion\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-stance-abortion\")\n\n# Tokenize the sample input text\nencoded_input = tokenizer(preprocessed_text, return_tensors='pt')\n\n# Forward pass through the model\nwith torch.no_grad():\n    output = model(**encoded_input)\n\n# Get the predicted label and score\npredicted_label = torch.argmax(output.logits, dim=1).item()\npredicted_score = torch.softmax(output.logits, dim=1).tolist()[0]\n\n# Get the label mapping\nmapping_link = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/mapping.txt\"\nresponse = urllib.request.urlopen(mapping_link)\nlabel_mapping = response.read().decode('utf-8').split(\"\\n\")\nlabel_mapping = [row.split('\\t') for row in label_mapping if len(row) > 0]\n\n# Map the predicted label to the corresponding sentiment\npredicted_sentiment = label_mapping[predicted_label][1]\n\n# Print the results\nprint(\"Sample Text:\", sample_text)\nprint(\"Predicted Sentiment:\", predicted_sentiment)\nprint(\"Predicted Score:\", predicted_score)","metadata":{"_uuid":"80a98338-c4a3-4bd0-9200-315430bef843","_cell_guid":"8694fe7f-011a-4ce7-8d1f-0292473f6437","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-28T10:39:03.129914Z","iopub.status.idle":"2023-06-28T10:39:03.130662Z","shell.execute_reply.started":"2023-06-28T10:39:03.130392Z","shell.execute_reply":"2023-06-28T10:39:03.130416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from wordcloud import WordCloud,STOPWORDS","metadata":{"_uuid":"514ffaba-b822-440a-abae-6bb754529909","_cell_guid":"4782379e-f96c-481e-8c93-882236661809","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-28T10:39:03.138893Z","iopub.status.idle":"2023-06-28T10:39:03.139454Z","shell.execute_reply.started":"2023-06-28T10:39:03.139185Z","shell.execute_reply":"2023-06-28T10:39:03.139208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.figure(figsize = (15,15)) # Text that is not Fake\n# wc = WordCloud(max_words = 2000 , width = 1600 , height = 800 , stopwords = STOPWORDS).generate(\" \".join(train_df[train_df.label == 1].text))\n# plt.imshow(wc , interpolation = 'bilinear')","metadata":{"_uuid":"8adc37c7-978e-4162-b14c-45474b1eecc3","_cell_guid":"00fbf0ad-3387-4f7d-98ce-ef2a7b201669","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-28T10:39:03.145142Z","iopub.status.idle":"2023-06-28T10:39:03.145808Z","shell.execute_reply.started":"2023-06-28T10:39:03.145554Z","shell.execute_reply":"2023-06-28T10:39:03.14558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pip install wordcloud","metadata":{"_uuid":"3db62853-08a0-4766-b1f7-dd8cd2668c47","_cell_guid":"2359bbc2-c2af-4ad8-b5ed-8e52ded2f5ef","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-28T10:39:03.15082Z","iopub.status.idle":"2023-06-28T10:39:03.151273Z","shell.execute_reply.started":"2023-06-28T10:39:03.151055Z","shell.execute_reply":"2023-06-28T10:39:03.151076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_texts = train_texts + valid_texts + test_texts\nall_texts","metadata":{"_uuid":"f34c992b-ba2d-4ff6-a5d9-20312bfe4e58","_cell_guid":"d19caec0-c0f8-4059-bccd-895f7c390991","collapsed":false,"scrolled":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-28T10:39:03.155884Z","iopub.status.idle":"2023-06-28T10:39:03.156578Z","shell.execute_reply.started":"2023-06-28T10:39:03.156338Z","shell.execute_reply":"2023-06-28T10:39:03.156363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\nflattened_texts = [word for sublist in all_texts for word in sublist]\nstring = ''.join(flattened_texts)\nnewlist = string.split(' ')\nword_frequencies = {}\nfor i in newlist:\n    if i in word_frequencies:\n        word_frequencies[i] +=1\n    else:\n        word_frequencies[i] = 1\n        \nprint(word_frequencies)","metadata":{"_uuid":"ab14b1db-87a6-4c02-837c-29f2d93c6ffc","_cell_guid":"fd2a90e0-412c-490d-acee-f700c90a0417","collapsed":false,"scrolled":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-28T10:39:03.15799Z","iopub.status.idle":"2023-06-28T10:39:03.158737Z","shell.execute_reply.started":"2023-06-28T10:39:03.158499Z","shell.execute_reply":"2023-06-28T10:39:03.158521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(max_words=1000, background_color='black', colormap='cool').generate_from_frequencies(word_frequencies)\n\nplt.figure(figsize=(10, 6))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","metadata":{"_uuid":"ef54737e-457c-4d88-87cb-28039e0837ff","_cell_guid":"55940801-ef83-4bae-888d-b9cbc9578360","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-28T10:39:03.160102Z","iopub.status.idle":"2023-06-28T10:39:03.160877Z","shell.execute_reply.started":"2023-06-28T10:39:03.160641Z","shell.execute_reply":"2023-06-28T10:39:03.160664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"72f11540-7be9-4328-91c7-a4ab7c8f5cf8","_cell_guid":"23a47846-c1ca-4e25-9345-1f230b86baf6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}